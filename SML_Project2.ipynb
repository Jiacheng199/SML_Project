{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "from colabcode import ColabCode\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#read train.json data\n",
    "orign_train_data = pd.read_json('train.json')\n",
    "\n",
    "#deep copy the original data\n",
    "train_data = copy.deepcopy(orign_train_data)\n",
    "\n",
    "#Get the authors list\n",
    "train_data_authors = train_data['authors']\n",
    "\n",
    "prolific_authors = []\n",
    "coauthors = []\n",
    "#Get the prolific authors list to train the model by removing the coauthors\n",
    "for author in train_data_authors:\n",
    "    p_authors = []\n",
    "    np_authors = []\n",
    "    for name in author:\n",
    "        if name < 100:\n",
    "            p_authors.append(name)\n",
    "        else:\n",
    "            np_authors.append(name)\n",
    "    prolific_authors.append(p_authors)\n",
    "    coauthors.append(np_authors)\n",
    "\n",
    "#add the prolific authors list to the train data\n",
    "train_data['coauthors'] = coauthors\n",
    "train_data['prolific_authors'] = prolific_authors\n",
    "\n",
    "#remove authors in the train data\n",
    "train_data = train_data.drop(['authors'], axis=1)\n",
    "\n",
    "p_a = train_data['prolific_authors']\n",
    "\n",
    "#read test.json data\n",
    "test_data = pd.read_json('test.json')\n",
    "\n",
    "#Pack the prediction result into a csv file\n",
    "def pack_result(result, file_name):\n",
    "    result = pd.DataFrame(result)\n",
    "    #change the 'ID' and 'Predict' column to int32\n",
    "    result['ID'] = result['ID'].astype('int32')\n",
    "    result['Predict'] = result['Predict'].astype('int32')\n",
    "    result.columns = ['ID', 'Predict']\n",
    "    result.to_csv(file_name, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets and make the no prolific paper has the -1 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([15889,  1205, 11909,  7138, 24813, 11313, 19843, 18356, 24884,\n",
      "             6921,\n",
      "            ...\n",
      "            16850,  6265, 22118, 11284, 11964, 21575,  5390,   860, 15795,\n",
      "            23654],\n",
      "           dtype='int64', length=20634)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Split the train data into training set and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['prolific_authors'],axis=1), p_a, test_size=0.2, random_state=42)\n",
    "\n",
    "#print the index of the training set\n",
    "print(X_train.index)\n",
    "\n",
    "#get the same index entries in the original train data\n",
    "X_train_orgin = orign_train_data.loc[X_train.index]\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    # if the author list is empty, add -1 to the list\n",
    "    if len(y_train.iloc[i]) == 0:\n",
    "        y_train.iloc[i].append(-1)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    # if the author list is empty, add -1 to the list\n",
    "    if len(y_test.iloc[i]) == 0:\n",
    "        y_test.iloc[i].append(-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that used to find essential information in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors = orign_train_data['authors']\n",
    "\n",
    "#find authors that author x used to worked with and how many times\n",
    "def find_author_x_work_with(author):\n",
    "    author_x_work_with = {}\n",
    "    author_x_paper = find_author_x_paper(author)\n",
    "    for paper in author_x_paper:\n",
    "        for ath in all_authors.iloc[paper]:\n",
    "            if ath != author:\n",
    "                if ath in author_x_work_with:\n",
    "                    author_x_work_with[ath] += 1\n",
    "                else:\n",
    "                    author_x_work_with[ath] = 1\n",
    "    return author_x_work_with\n",
    "\n",
    "#find which paper that author x participated\n",
    "def find_author_x_paper(author):\n",
    "    author_x_paper = []\n",
    "    for i in range(len(all_authors)):\n",
    "        if author in all_authors.iloc[i]:\n",
    "            author_x_paper.append(i)\n",
    "    return author_x_paper\n",
    "\n",
    "#whether the author x and author y worked with each other\n",
    "def is_author_x_work_with_author_y(author_x, author_y):\n",
    "    author_x_paper = find_author_x_paper(author_x)\n",
    "    author_y_paper = find_author_x_paper(author_y)\n",
    "    for paper in author_x_paper:\n",
    "        if paper in author_y_paper:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#the years of author x collaborated with author y\n",
    "def year_author_x_work_with_author_y(author_x, author_y):\n",
    "    years = []\n",
    "    author_x_paper = find_author_x_paper(author_x)\n",
    "    author_y_paper = find_author_x_paper(author_y)\n",
    "    for paper in author_x_paper:\n",
    "        if paper in author_y_paper:\n",
    "            years.append(orign_train_data.iloc[paper]['year'])\n",
    "    # remove the duplicate years\n",
    "    years = list(set(years))\n",
    "    return years\n",
    "\n",
    "#get the prolific authors that these authors all worked with\n",
    "def get_prolific_authors(authors):\n",
    "    prolific_authors = []\n",
    "    for author in authors:\n",
    "        prolific_authors.append(find_author_x_work_with(author))\n",
    "    #get the prolific authors that these authors all worked with\n",
    "    prolific_authors = set.intersection(*map(set, prolific_authors))\n",
    "\n",
    "    p_a = []\n",
    "    for author in prolific_authors:\n",
    "        if author < 100:\n",
    "            p_a.append(author)\n",
    "    return p_a\n",
    "#find the prolific authors that the authors worked with (at least one of given authors worked with)\n",
    "def get_authors_prolific_atleast_one(authors):\n",
    "    prolific_authors = []\n",
    "    for author in authors:\n",
    "        prolific_authors.append(find_author_x_work_with(author))\n",
    "    #get the prolific authors that these authors all worked with\n",
    "    prolific_authors = set.union(*map(set, prolific_authors))\n",
    "\n",
    "    p_a = []\n",
    "    for author in prolific_authors:\n",
    "        if author < 100:\n",
    "            p_a.append(author)\n",
    "    return p_a\n",
    "\n",
    "#get all sub set of the given number list\n",
    "def get_all_sub_set(nums):\n",
    "    result = [[]]\n",
    "    for num in nums:\n",
    "        result += [item + [num] for item in result]\n",
    "    # remove null set\n",
    "    result.remove([])\n",
    "    return result\n",
    "\n",
    "#Author anylysis\n",
    "def author_analysis(author):\n",
    "    author_x_work_with = find_author_x_work_with(author)\n",
    "    author_x_paper = find_author_x_paper(author)\n",
    "    author_x_work_with = sorted(author_x_work_with.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print('Author', author, 'has', len(author_x_paper), 'papers')\n",
    "    print('Author', author, 'has worked with', len(author_x_work_with), 'authors')\n",
    "    print('Author', author, 'has worked with author - ', author_x_work_with[0][0], 'the most times\\n')\n",
    "    print('the paper that author', author, 'has participated', author_x_paper)\n",
    "    \n",
    "    print('--top 5 author that author(include non-prolific authors)', author, 'has worked with the most times--')\n",
    "\n",
    "    print('the ratio of this author work with', author_x_work_with[0][0], 'is', author_x_work_with[0][1]/len(author_x_paper), 'the number of collaboration is', author_x_work_with[0][1])\n",
    "    print('the year that author', author, 'work with author', author_x_work_with[0][0], 'is', year_author_x_work_with_author_y(author, author_x_work_with[0][0]),'\\n')\n",
    "    print('the ratio of this author work with', author_x_work_with[1][0], 'is', author_x_work_with[1][1]/len(author_x_paper), 'the number of collaboration is', author_x_work_with[1][1])\n",
    "    print('the ratio of this author work with', author_x_work_with[2][0], 'is', author_x_work_with[2][1]/len(author_x_paper), 'the number of collaboration is', author_x_work_with[2][1])\n",
    "    print('the ratio of this author work with', author_x_work_with[3][0], 'is', author_x_work_with[3][1]/len(author_x_paper), 'the number of collaboration is', author_x_work_with[3][1])\n",
    "    print('the ratio of this author work with', author_x_work_with[4][0], 'is', author_x_work_with[4][1]/len(author_x_paper), 'the number of collaboration is', author_x_work_with[4][1])\n",
    "\n",
    "    print('Prolific authors that worked with and the time they worked togeth', author, '\\n')\n",
    "    for i in range(len(author_x_work_with)):\n",
    "        if author_x_work_with[i][0] < 100:\n",
    "            print('author id:',author_x_work_with[i][0],'  times:' ,author_x_work_with[i][1])\n",
    "            print('the venue of author', author, 'work with author', author_x_work_with[i][0], 'is', year_author_x_work_with_author_y(author, author_x_work_with[i][0]),'\\n')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(get_all_sub_set([1,2,3,4])))\n",
    "print(len(get_all_sub_set([1,2,3,4,5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering process for the logistic regression model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible_prolific_authors_rate {70: 0.5, 87: 0.5, 39: 0.5}\n",
      "the i entry has been featured 0\n",
      "possible_prolific_authors_rate {}\n",
      "the i entry has been featured 1\n",
      "possible_prolific_authors_rate {36: 0.5, 10: 0.5}\n",
      "the i entry has been featured 2\n",
      "possible_prolific_authors_rate {32: 0.3333333333333333, 59: 0.6666666666666666, 6: 0.3333333333333333, 17: 0.3333333333333333, 18: 0.3333333333333333, 36: 0.3333333333333333, 48: 0.3333333333333333, 49: 0.3333333333333333, 51: 0.3333333333333333, 58: 0.3333333333333333, 57: 0.3333333333333333, 62: 0.3333333333333333, 72: 0.3333333333333333, 74: 0.3333333333333333, 78: 0.3333333333333333, 81: 0.3333333333333333, 83: 0.3333333333333333, 84: 0.3333333333333333, 92: 0.3333333333333333, 99: 0.3333333333333333, 70: 0.3333333333333333}\n",
      "the i entry has been featured 3\n",
      "possible_prolific_authors_rate {6: 0.5, 8: 0.5, 14: 0.5, 29: 0.5, 32: 0.5, 37: 0.5, 51: 0.5, 57: 0.5, 59: 0.5, 60: 0.5, 62: 0.5, 69: 0.5, 73: 0.5, 87: 0.5}\n",
      "the i entry has been featured 4\n",
      "possible_prolific_authors_rate {14: 1.0, 22: 0.5, 26: 0.5, 27: 0.5, 31: 0.5, 42: 0.5, 48: 0.5, 51: 0.5, 58: 0.5, 67: 0.5, 70: 1.0, 71: 0.5, 74: 0.5, 75: 0.5, 81: 0.5, 90: 0.5, 98: 0.5, 46: 0.5, 47: 0.5, 53: 0.5}\n",
      "the i entry has been featured 5\n",
      "possible_prolific_authors_rate {39: 1.0, 60: 0.5, 8: 0.5, 92: 0.5}\n",
      "the i entry has been featured 6\n",
      "possible_prolific_authors_rate {11: 1.0, 12: 1.0, 32: 1.0, 53: 1.0, 59: 1.0, 74: 1.0, 86: 1.0, 89: 1.0, 97: 1.0}\n",
      "the i entry has been featured 7\n",
      "possible_prolific_authors_rate {16: 0.3333333333333333, 41: 0.3333333333333333, 56: 0.3333333333333333, 58: 0.3333333333333333, 83: 0.3333333333333333, 88: 0.3333333333333333, 97: 0.3333333333333333}\n",
      "the i entry has been featured 8\n",
      "possible_prolific_authors_rate {}\n",
      "the i entry has been featured 9\n",
      "possible_prolific_authors_rate {47: 0.25}\n",
      "the i entry has been featured 10\n",
      "possible_prolific_authors_rate {}\n",
      "the i entry has been featured 11\n",
      "possible_prolific_authors_rate {81: 0.3333333333333333, 26: 0.3333333333333333}\n",
      "the i entry has been featured 12\n",
      "possible_prolific_authors_rate {56: 0.3333333333333333, 51: 0.3333333333333333}\n",
      "the i entry has been featured 13\n",
      "possible_prolific_authors_rate {11: 1.0, 83: 0.3333333333333333, 62: 0.3333333333333333}\n",
      "the i entry has been featured 14\n",
      "possible_prolific_authors_rate {20: 0.5, 43: 1.0, 48: 0.5, 54: 1.0}\n",
      "the i entry has been featured 15\n",
      "possible_prolific_authors_rate {14: 0.25, 19: 0.25, 23: 0.25, 51: 0.25, 57: 0.25, 81: 0.25, 90: 0.25, 91: 0.25}\n",
      "the i entry has been featured 16\n",
      "possible_prolific_authors_rate {3: 0.5, 84: 0.5}\n",
      "the i entry has been featured 17\n",
      "possible_prolific_authors_rate {41: 0.2, 58: 0.4, 49: 0.6, 6: 0.2, 11: 0.2, 55: 0.2, 62: 0.2, 65: 0.2, 74: 0.2, 73: 0.2, 83: 0.2, 84: 0.2, 92: 0.2, 97: 0.2}\n",
      "the i entry has been featured 18\n",
      "possible_prolific_authors_rate {}\n",
      "the i entry has been featured 19\n",
      "possible_prolific_authors_rate {27: 1.0}\n",
      "the i entry has been featured 20\n",
      "possible_prolific_authors_rate {28: 0.5}\n",
      "the i entry has been featured 21\n",
      "possible_prolific_authors_rate {}\n",
      "the i entry has been featured 22\n",
      "possible_prolific_authors_rate {44: 0.5, 45: 0.5, 27: 1.0}\n",
      "the i entry has been featured 23\n",
      "possible_prolific_authors_rate {}\n",
      "the i entry has been featured 24\n",
      "possible_prolific_authors_rate {66: 0.25, 32: 0.5, 75: 0.5, 87: 0.5, 28: 0.25, 53: 0.25, 83: 0.25}\n",
      "the i entry has been featured 25\n",
      "possible_prolific_authors_rate {6: 0.5, 19: 0.5, 23: 0.5, 26: 0.5, 39: 0.5, 62: 0.5, 79: 1.0, 38: 0.5}\n",
      "the i entry has been featured 26\n",
      "possible_prolific_authors_rate {69: 0.25, 75: 0.25, 59: 0.25}\n",
      "the i entry has been featured 27\n",
      "possible_prolific_authors_rate {32: 0.25}\n",
      "the i entry has been featured 28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6104/1677544935.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mfeature_engineering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6104/1677544935.py\u001b[0m in \u001b[0;36mfeature_engineering\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m#find all possible prolific authors in all possible sub sets of given paper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msub_set\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msub_sets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0mprolific_authors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_prolific_authors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mprolific_author\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprolific_authors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0mp_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6104/3240987979.py\u001b[0m in \u001b[0;36mget_prolific_authors\u001b[1;34m(authors)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mprolific_authors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mauthor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mauthors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mprolific_authors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_author_x_work_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;31m#get the prolific authors that these authors all worked with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mprolific_authors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprolific_authors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6104/3240987979.py\u001b[0m in \u001b[0;36mfind_author_x_work_with\u001b[1;34m(author)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfind_author_x_work_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mauthor_x_work_with\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mauthor_x_paper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_author_x_paper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpaper\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mauthor_x_paper\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0math\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_authors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpaper\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6104/3240987979.py\u001b[0m in \u001b[0;36mfind_author_x_paper\u001b[1;34m(author)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mauthor_x_paper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_authors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mauthor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_authors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mauthor_x_paper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mauthor_x_paper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yojc1\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yojc1\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1549\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1551\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yojc1\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m    128\u001b[0m     if isinstance(key, (ABCSeries, np.ndarray, ABCIndex)) or (\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mis_array_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     ):\n\u001b[0;32m    131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def feature_engineering(train,test):\n",
    "    new_featurs = {}\n",
    "    #how many authors that a prolific author has worked witha in the same paper\n",
    "    new_featurs['rate'] = []\n",
    "    #how many paper that the prolific author has published on the given venue with the respect to the all papers that the prolific author has published\n",
    "    new_featurs['same_venue'] = []\n",
    "    #the count of total collaboration of prolific author with all the coauthors\n",
    "    new_featurs['total_col'] = []\n",
    "    #how many coauthors in the given data\n",
    "    new_featurs['coauthors_count'] = []\n",
    "    new_featurs['is_author'] = []\n",
    "\n",
    "    for i in range(len(train)):\n",
    "        authors = train.iloc[i]['coauthors']\n",
    "        #the paper that have only one author and it is also a prolific author will have no coauthors\n",
    "        if len(authors) != 0:\n",
    "            possible_prolific_authors_rate = {}\n",
    "            all_prolific_authors = get_authors_prolific_atleast_one(authors)\n",
    "\n",
    "\n",
    "            #make sure don't add empty rows to the new features\n",
    "            if len(possible_prolific_authors_rate) != 0:\n",
    "                for prolific_author in possible_prolific_authors_rate.keys():\n",
    "                    new_featurs['rate'].append(possible_prolific_authors_rate[prolific_author])\n",
    "                    new_featurs['same_venue'].append(0)\n",
    "                    new_featurs['total_col'].append(0)\n",
    "                    new_featurs['coauthors_count'].append(len(authors))\n",
    "                    new_featurs['is_author'].append(1)\n",
    "\n",
    "            print('possible_prolific_authors_rate', possible_prolific_authors_rate)\n",
    "        print('the i entry has been featured', i)\n",
    "\n",
    "    new_featurs = pd.DataFrame(new_featurs)\n",
    "    return possible_prolific_authors_rate\n",
    "\n",
    "#create a logistic regression model\n",
    "def logistic_regression_model(X_train, y_train, penalty='l2', C=1.0, solver='liblinear', max_iter=100, l1_ratio=None):\n",
    "    logistic_regression = LogisticRegression(penalty, C, solver, max_iter, l1_ratio)\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "    return logistic_regression\n",
    "\n",
    "# Determine whether the author is the author of the paper using logistic regression\n",
    "def is_prolific_author(author,paper_info):\n",
    "    authors = paper_info['coauthors']\n",
    "    venue = paper_info['venue']\n",
    "    return 1\n",
    "\n",
    "#\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb5a402466d28a1821bc84d43b10ee2d72ed7aa57f13d2adb493918648b6969f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
