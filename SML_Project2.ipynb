{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wget'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9j/ynhzv7dd5yz6hy726z6_pqc00000gn/T/ipykernel_37423/1553729772.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolabcode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColabCode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mColabCode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1234\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/colabcode/code.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, port, password, authtoken, mount_drive, code, lab)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_install_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_install_extensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/colabcode/code.py\u001b[0m in \u001b[0;36m_install_code\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_install_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"wget\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"https://code-server.dev/install.sh\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         subprocess.run(\n\u001b[1;32m     51\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m\"sh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"install.sh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--version\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{CODESERVER_VERSION}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    949\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1819\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wget'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "from colabcode import ColabCode\n",
    "\n",
    "ColabCode(port=10000, password=\"1234\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#read train.json data\n",
    "orign_train_data = pd.read_json('train.json')\n",
    "\n",
    "#deep copy the original data\n",
    "train_data = copy.deepcopy(orign_train_data)\n",
    "\n",
    "#Get the authors list\n",
    "train_data_authors = train_data['authors']\n",
    "\n",
    "prolific_authors = []\n",
    "coauthors = []\n",
    "#Get the prolific authors list to train the model by removing the coauthors\n",
    "for author in train_data_authors:\n",
    "    p_authors = []\n",
    "    np_authors = []\n",
    "    for name in author:\n",
    "        if name < 100:\n",
    "            p_authors.append(name)\n",
    "        else:\n",
    "            np_authors.append(name)\n",
    "    prolific_authors.append(p_authors)\n",
    "    coauthors.append(np_authors)\n",
    "\n",
    "#add the prolific authors list to the train data\n",
    "train_data['coauthors'] = coauthors\n",
    "train_data['prolific_authors'] = prolific_authors\n",
    "\n",
    "#remove authors in the train data\n",
    "train_data = train_data.drop(['authors'], axis=1)\n",
    "\n",
    "p_a = train_data['prolific_authors']\n",
    "\n",
    "#read test.json data\n",
    "test_data = pd.read_json('test.json')\n",
    "\n",
    "#Pack the prediction result into a csv file\n",
    "def pack_result(result, file_name):\n",
    "    result = pd.DataFrame(result)\n",
    "    #change the 'ID' and 'Predict' column to int32\n",
    "    result['ID'] = result['ID'].astype('int32')\n",
    "    result['Predict'] = result['Predict'].astype('int32')\n",
    "    result.columns = ['ID', 'Predict']\n",
    "    result.to_csv(file_name, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets and make the no prolific paper has the -1 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Split the train data into training set and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data.drop(['prolific_authors'],axis=1), p_a, test_size=0.2, random_state=42)\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    # if the author list is empty, add -1 to the list\n",
    "    if len(y_train.iloc[i]) == 0:\n",
    "        y_train.iloc[i].append(-1)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    # if the author list is empty, add -1 to the list\n",
    "    if len(y_test.iloc[i]) == 0:\n",
    "        y_test.iloc[i].append(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that used to find essential information in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_authors = orign_train_data['authors']\n",
    "\n",
    "#find authors that author x used to worked with and how many times\n",
    "def find_author_x_work_with(author):\n",
    "    author_x_work_with = {}\n",
    "    author_x_paper = find_author_x_paper(author)\n",
    "    for paper in author_x_paper:\n",
    "        for ath in all_authors.iloc[paper]:\n",
    "            if ath != author:\n",
    "                if ath in author_x_work_with:\n",
    "                    author_x_work_with[ath] += 1\n",
    "                else:\n",
    "                    author_x_work_with[ath] = 1\n",
    "    return author_x_work_with\n",
    "\n",
    "#find which paper that author x participated\n",
    "def find_author_x_paper(author):\n",
    "    author_x_paper = []\n",
    "    for i in range(len(all_authors)):\n",
    "        if author in all_authors.iloc[i]:\n",
    "            author_x_paper.append(i)\n",
    "    return author_x_paper\n",
    "\n",
    "#whether the author x and author y worked with each other\n",
    "def is_author_x_work_with_author_y(author_x, author_y):\n",
    "    author_x_paper = find_author_x_paper(author_x)\n",
    "    author_y_paper = find_author_x_paper(author_y)\n",
    "    for paper in author_x_paper:\n",
    "        if paper in author_y_paper:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#the years of author x collaborated with author y\n",
    "def year_author_x_work_with_author_y(author_x, author_y):\n",
    "    years = []\n",
    "    author_x_paper = find_author_x_paper(author_x)\n",
    "    author_y_paper = find_author_x_paper(author_y)\n",
    "    for paper in author_x_paper:\n",
    "        if paper in author_y_paper:\n",
    "            years.append(orign_train_data.iloc[paper]['year'])\n",
    "    # remove the duplicate years\n",
    "    years = list(set(years))\n",
    "    return years\n",
    "\n",
    "#get the prolific authors that these authors all worked with\n",
    "def get_prolific_authors(authors):\n",
    "    prolific_authors = []\n",
    "    for author in authors:\n",
    "        prolific_authors.append(find_author_x_work_with(author))\n",
    "    #get the prolific authors that these authors all worked with\n",
    "    prolific_authors = set.intersection(*map(set, prolific_authors))\n",
    "\n",
    "    p_a = []\n",
    "    for author in prolific_authors:\n",
    "        if author < 100:\n",
    "            p_a.append(author)\n",
    "    return p_a\n",
    "#find the prolific authors that the authors worked with (at least one of given authors worked with)\n",
    "def get_authors_prolicific_atleast_one(authors):\n",
    "    prolific_authors = []\n",
    "    for author in authors:\n",
    "        prolific_authors.append(find_author_x_work_with(author))\n",
    "    #get the prolific authors that these authors all worked with\n",
    "    prolific_authors = set.union(*map(set, prolific_authors))\n",
    "\n",
    "    p_a = []\n",
    "    for author in prolific_authors:\n",
    "        if author < 100:\n",
    "            p_a.append(author)\n",
    "    return p_a\n",
    "\n",
    "#get all sub set of the given number list\n",
    "def get_all_sub_set(nums):\n",
    "    result = [[]]\n",
    "    for num in nums:\n",
    "        result += [item + [num] for item in result]\n",
    "    # remove null set\n",
    "    result.remove([])\n",
    "    return result\n",
    "\n",
    "#Author anylysis\n",
    "def author_analysis(author):\n",
    "    author_x_work_with = find_author_x_work_with(author)\n",
    "    author_x_paper = find_author_x_paper(author)\n",
    "    author_x_work_with = sorted(author_x_work_with.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print('Author', author, 'has', len(author_x_paper), 'papers')\n",
    "    print('Author', author, 'has worked with', len(author_x_work_with), 'authors')\n",
    "    print('Author', author, 'has worked with author - ', author_x_work_with[0][0], 'the most times\\n')\n",
    "    print('the paper that author', author, 'has participated', author_x_paper)\n",
    "    \n",
    "    print('--top 5 author that author(include non-prolific authors)', author, 'has worked with the most times--')\n",
    "\n",
    "    print('the ratio of this author work with', author_x_work_with[0][0], 'is', author_x_work_with[0][1]/len(author_x_paper), 'the number of collaboration is', author_x_work_with[0][1])\n",
    "    print('the year that author', author, 'work with author', author_x_work_with[0][0], 'is', year_author_x_work_with_author_y(author, author_x_work_with[0][0]),'\\n')\n",
    "    print('the ratio of this author work with', author_x_work_with[1][0], 'is', author_x_work_with[1][1]/len(author_x_paper), 'the number of collaboration is', author_x_work_with[1][1])\n",
    "    print('the ratio of this author work with', author_x_work_with[2][0], 'is', author_x_work_with[2][1]/len(author_x_paper), 'the number of collaboration is', author_x_work_with[2][1])\n",
    "    print('the ratio of this author work with', author_x_work_with[3][0], 'is', author_x_work_with[3][1]/len(author_x_paper), 'the number of collaboration is', author_x_work_with[3][1])\n",
    "    print('the ratio of this author work with', author_x_work_with[4][0], 'is', author_x_work_with[4][1]/len(author_x_paper), 'the number of collaboration is', author_x_work_with[4][1])\n",
    "\n",
    "    print('Prolific authors that worked with and the time they worked togeth', author, '\\n')\n",
    "    for i in range(len(author_x_work_with)):\n",
    "        if author_x_work_with[i][0] < 100:\n",
    "            print('author id:',author_x_work_with[i][0],'  times:' ,author_x_work_with[i][1])\n",
    "            print('the venue of author', author, 'work with author', author_x_work_with[i][0], 'is', year_author_x_work_with_author_y(author, author_x_work_with[i][0]),'\\n')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(get_all_sub_set([1,2,3,4])))\n",
    "print(len(get_all_sub_set([1,2,3,4,5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering process for the logistic regression model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible_prolific_authors_rate {70: 0.5, 87: 0.5, 39: 0.5}\n",
      "the i entry has been featured 0\n",
      "possible_prolific_authors_rate {}\n",
      "the i entry has been featured 1\n",
      "possible_prolific_authors_rate {36: 0.5, 10: 0.5}\n",
      "the i entry has been featured 2\n",
      "possible_prolific_authors_rate {32: 0.3333333333333333, 59: 0.6666666666666666, 6: 0.3333333333333333, 17: 0.3333333333333333, 18: 0.3333333333333333, 36: 0.3333333333333333, 48: 0.3333333333333333, 49: 0.3333333333333333, 51: 0.3333333333333333, 58: 0.3333333333333333, 57: 0.3333333333333333, 62: 0.3333333333333333, 72: 0.3333333333333333, 74: 0.3333333333333333, 78: 0.3333333333333333, 81: 0.3333333333333333, 83: 0.3333333333333333, 84: 0.3333333333333333, 92: 0.3333333333333333, 99: 0.3333333333333333, 70: 0.3333333333333333}\n",
      "the i entry has been featured 3\n",
      "possible_prolific_authors_rate {6: 0.5, 8: 0.5, 14: 0.5, 29: 0.5, 32: 0.5, 37: 0.5, 51: 0.5, 57: 0.5, 59: 0.5, 60: 0.5, 62: 0.5, 69: 0.5, 73: 0.5, 87: 0.5}\n",
      "the i entry has been featured 4\n",
      "possible_prolific_authors_rate {14: 1.0, 22: 0.5, 26: 0.5, 27: 0.5, 31: 0.5, 42: 0.5, 48: 0.5, 51: 0.5, 58: 0.5, 67: 0.5, 70: 1.0, 71: 0.5, 74: 0.5, 75: 0.5, 81: 0.5, 90: 0.5, 98: 0.5, 46: 0.5, 47: 0.5, 53: 0.5}\n",
      "the i entry has been featured 5\n",
      "possible_prolific_authors_rate {39: 1.0, 60: 0.5, 8: 0.5, 92: 0.5}\n",
      "the i entry has been featured 6\n",
      "possible_prolific_authors_rate {11: 1.0, 12: 1.0, 32: 1.0, 53: 1.0, 59: 1.0, 74: 1.0, 86: 1.0, 89: 1.0, 97: 1.0}\n",
      "the i entry has been featured 7\n",
      "possible_prolific_authors_rate {16: 0.3333333333333333, 41: 0.3333333333333333, 56: 0.3333333333333333, 58: 0.3333333333333333, 83: 0.3333333333333333, 88: 0.3333333333333333, 97: 0.3333333333333333}\n",
      "the i entry has been featured 8\n",
      "possible_prolific_authors_rate {}\n",
      "the i entry has been featured 9\n",
      "possible_prolific_authors_rate {47: 0.25}\n",
      "the i entry has been featured 10\n",
      "possible_prolific_authors_rate {}\n",
      "the i entry has been featured 11\n",
      "possible_prolific_authors_rate {81: 0.3333333333333333, 26: 0.3333333333333333}\n",
      "the i entry has been featured 12\n",
      "possible_prolific_authors_rate {56: 0.3333333333333333, 51: 0.3333333333333333}\n",
      "the i entry has been featured 13\n",
      "possible_prolific_authors_rate {11: 1.0, 83: 0.3333333333333333, 62: 0.3333333333333333}\n",
      "the i entry has been featured 14\n",
      "possible_prolific_authors_rate {20: 0.5, 43: 1.0, 48: 0.5, 54: 1.0}\n",
      "the i entry has been featured 15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9j/ynhzv7dd5yz6hy726z6_pqc00000gn/T/ipykernel_31204/1677544935.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mfeature_engineering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/9j/ynhzv7dd5yz6hy726z6_pqc00000gn/T/ipykernel_31204/1677544935.py\u001b[0m in \u001b[0;36mfeature_engineering\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m#find all possible prolific authors in all possible sub sets of given paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msub_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_sets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mprolific_authors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prolific_authors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mprolific_author\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprolific_authors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mp_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9j/ynhzv7dd5yz6hy726z6_pqc00000gn/T/ipykernel_31204/3240987979.py\u001b[0m in \u001b[0;36mget_prolific_authors\u001b[0;34m(authors)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprolific_authors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mauthor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mauthors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mprolific_authors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_author_x_work_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;31m#get the prolific authors that these authors all worked with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprolific_authors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprolific_authors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9j/ynhzv7dd5yz6hy726z6_pqc00000gn/T/ipykernel_31204/3240987979.py\u001b[0m in \u001b[0;36mfind_author_x_work_with\u001b[0;34m(author)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_author_x_work_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mauthor_x_work_with\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mauthor_x_paper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_author_x_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpaper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mauthor_x_paper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0math\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_authors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpaper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9j/ynhzv7dd5yz6hy726z6_pqc00000gn/T/ipykernel_31204/3240987979.py\u001b[0m in \u001b[0;36mfind_author_x_paper\u001b[0;34m(author)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mauthor_x_paper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_authors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mauthor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_authors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mauthor_x_paper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauthor_x_paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def feature_engineering(train,test):\n",
    "    new_featurs = {}\n",
    "    #how many authors that a prolific author has worked witha in the same paper\n",
    "    new_featurs['rate'] = []\n",
    "    #how many paper that the prolific author has published on the given venue with the respect to the all papers that the prolific author has published\n",
    "    new_featurs['same_venue'] = []\n",
    "    #the count of total collaboration of prolific author with all the coauthors\n",
    "    new_featurs['total_col'] = []\n",
    "    #how many coauthors in the given data\n",
    "    new_featurs['coauthors_count'] = []\n",
    "    new_featurs['is_author'] = []\n",
    "\n",
    "    for i in range(len(train)):\n",
    "        authors = train.iloc[i]['coauthors']\n",
    "        #the paper that have only one author and it is also a prolific author will have no coauthors\n",
    "        if len(authors) != 0:\n",
    "            possible_prolific_authors_rate = {}\n",
    "            sub_sets = get_all_sub_set(authors)\n",
    "\n",
    "            #find all possible prolific authors in all possible sub sets of given paper\n",
    "            for sub_set in sub_sets:\n",
    "                prolific_authors = get_prolific_authors(sub_set)\n",
    "                for prolific_author in prolific_authors:\n",
    "                    p_rate = len(sub_set)/len(authors)\n",
    "                    if prolific_author not in possible_prolific_authors_rate:\n",
    "                        possible_prolific_authors_rate[prolific_author] = p_rate\n",
    "                    else:\n",
    "                        if possible_prolific_authors_rate[prolific_author] < p_rate:\n",
    "                            possible_prolific_authors_rate[prolific_author] = p_rate\n",
    "\n",
    "            #make sure don't add empty rows to the new features\n",
    "            if len(possible_prolific_authors_rate) != 0:\n",
    "                for prolific_author in possible_prolific_authors_rate.keys():\n",
    "    \n",
    "                    author_id = prolific_author\n",
    "\n",
    "            print('possible_prolific_authors_rate', possible_prolific_authors_rate)\n",
    "        print('the i entry has been featured', i)\n",
    "\n",
    "    new_featurs = pd.DataFrame(new_featurs)\n",
    "    return possible_prolific_authors_rate\n",
    "\n",
    "#create a logistic regression model\n",
    "def logistic_regression_model(X_train, y_train, penalty='l2', C=1.0, solver='liblinear', max_iter=100, l1_ratio=None):\n",
    "    logistic_regression = LogisticRegression(penalty, C, solver, max_iter, l1_ratio)\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "    return logistic_regression\n",
    "\n",
    "# Deternqmine whether the author is the author of the paper using logistic regression\n",
    "def is_prolific_author(author,paper_info):\n",
    "    authors = paper_info['coauthors']\n",
    "    venue = paper_info['venue']\n",
    "    return 1\n",
    "    \n",
    "feature_engineering(X_train[3:90], X_test[0:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fb6f22b9ea3684756870944b5f3fb664fed3c82022a08a9b2c6685fd75d4878"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
